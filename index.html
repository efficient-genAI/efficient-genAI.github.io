
<!DOCTYPE html>
<html lang="en-US">

  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<div style="text-align: left; max-width: 800px; margin: auto;">
<title>Efficient Text-to-Image/Video modeling| [“CVPR 2025 Tutorial”, “June, 12, 2025”, “Nashville, USA”]</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Efficient Text-to-Image/Video modeling" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="[“CVPR 2025 Tutorial”, “June, 12, 2025”, “Nashville, USA”]" />
<meta property="og:description" content="[“CVPR 2025 Tutorial”, “June, 12, 2025”, “Nashville, USA”]" />
<link rel="canonical" href="https://efficient-genAI.github.io/" />
<meta property="og:url" content="https://efficient-genAI.github.io/" />
<meta property="og:site_name" content="Efficient Text-to-Image/Video modeling" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Efficient Text-to-Image/Video modeling" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"[“CVPR 2025 Tutorial”, “June, 12, 2025”, “NashVille, USA”]","headline":"Efficient Text-to-Image/Video modeling","name":"Efficient Text-to-Image/Video modeling","url":"https://efficient-genAI.github.io/"}</script>
<!-- End Jekyll SEO tag -->

    <meta property="og:title" content='Efficient Text-to-Image/Video modeling - CVPR2025'/>
    <meta property="og:image" content="efficient-genAI.github.io/cvpr2025_nashville_tn.jpeg">
    <meta property="og:image:type" content="image/jpeg">
    <meta property="og:image:width" content="200">
    <meta property="og:image:height" content="200">
    <meta property="og:type" content='website'/>
    <meta name="description" content="CVPR 2025 TutorialJune, 2025 Nashville, USA"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#39275B">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=6e64313460609e93346c4862a60afa3aebec1d2f">
    
  </head>
  <body>
  <style> 
    .logo {
      display: block;
      margin-left: auto;
      margin-right: auto;
      width: 50%;
      background-color: #000000; 
    } 
    
    .page-header1 {
  background-image: url('cvpr2025_nashville_tn.jpeg');
  background-repeat: no-repeat;
  background-size: 100% ;
  background-position: center;
  padding-bottom: 1rem;
  background-color: #ffffff;
    }
  .page-header2 {
  background-color: #ffffff;
  background-image: linear-gradient(120deg, #ffffff, #ffffff);
  }
    .btn {
  display: inline-block;
  margin-bottom: 1rem;
  color: rgba(0, 0, 0, 0.897);
  background-color: rgba(0, 0, 0, 0.8);
  border-color: rgba(0, 0, 0, 0.918);
  border-style: solid;
  border-width: 1px;
  border-radius: 0.3rem;
  transition: color 0.2s, background-color 0.2s, border-color 0.2s;
    }
  </style>
    <section class="page-header page-header1">
    <div style="text-align: left; max-width: 800px; margin: auto;">
      <!-- <img alt="logo" src="pics/placehold-logo.svg" class = "logo" > -->
      <h1 class="project-name" style="color:#ffffff; ">Efficient Text-to-Image/Video modeling</h1>
     <h2 class="project-tagline" style="font-size: 32px; color:#ffffff ;  opacity: 100%; "><span>CVPR 2025 Tutorial</span><br><span>June, 12, 2024</span><br><span>Nashville, USA</span><br></h2>
   
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
       
       
    <a href="./index.html" class="btn" style="color:#ffffff ; font-size: large; text-shadow: -0.1px -0.1px 0 #000000, 0.1px -0.1px 0 #000000, -0.1px 0.1px 0 #000000, 0.1px 0.1px 0 #000000;">Overview</a>
  
       
    <a href="./index.html#speakers" class="btn" style="color:#ffffff ; font-size: large; text-shadow: -0.1px -0.1px 0 #000000, 0.1px -0.1px 0 #000000, -0.1px 0.1px 0 #000000, 0.1px 0.1px 0 #000000;">Speakers</a>
  
       
    <a href="./index.html#schedule" class="btn" style="color:#ffffff ; font-size: large; text-shadow: -0.1px -0.1px 0 #000000, 0.1px -0.1px 0 #000000, -0.1px 0.1px 0 #000000, 0.1px 0.1px 0 #000000;">Schedule</a>

    </section>
    
   
    <section class="main-content">
      <style> 
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 75%;
} </style>

<h1 id="overview">Overview</h1>
<div style="text-align: left; max-width: 800px; margin: auto;">
We are witnessing groundbreaking results in image-to-text and image-to-video models. However, the generation process with these models is iterative and computationally expensive, requiring multiple sampling steps through large models. There is a growing need to make these algorithms faster for serving millions of users without the use of too many GPUs/TPUs. In this course, we will focus on techniques such as progressive parallel decoding, distillation methods, and Markov Random Fields to achieve speedup on generative models. </div>

<h1 id="peakers">Speakers</h1>
<div style="display: flex; flex-wrap: wrap; justify-content: space-around;">

  <div style="width:45%; margin: 1%;">
    <a href="https://en.wikipedia.org/wiki/Richard_Hartley_(scientist)">
      <img alt="Richard Hartley" src="richard_hartley.jpeg" height="200" width="200" style="border-radius: 50%; object-fit: cover; " />
    </a><br />
  <a href="https://en.wikipedia.org/wiki/Richard_Hartley_(scientist)">Richard Hartley</a><br />
    Australian National University
  </div>
  
  <div style="width:45%; margin: 1%;">
    <a href="https://research.google/people/106837/?&type=google">
      <img alt="Sadeep Jayasumana" src="sadeep_headshot.jpg" height="200" width="200" style="border-radius: 50%; object-fit: cover; " />
    </a><br />
  <a href="https://research.google/people/106837/?&type=google"> Sadeep Jayasumana</a><br />
    OCTAVE | Ex-Google AI Research
  </div>
  
  <div style="width:45%; margin: 1%;">
    <a href="https://amakadia.github.io/">
      <img alt="Ameesh Makadia" src="ameesh.jpg" height="200" width="200" style="border-radius: 50%; object-fit: cover; " />
    </a><br />
  <a href="https://amakadia.github.io/">Ameesh Makadia</a><br />
    Google Research
  </div>

      <div style="width:45%; margin: 1%;">
    <a href="https://users.cs.utah.edu/~srikumar/">
      <img alt="Srikumar Ramalingam" src="srikumar_headshot.png" height="200" width="200" style="border-radius: 50%; object-fit: cover; " />
    </a><br />
  <a href="https://users.cs.utah.edu/~srikumar/">Srikumar Ramalingam</a><br />
    Google Research
  </div>




  <div style="width:45%; margin: 1%;">
  <a href="">
   
  </a><br />
  <a href=""></a><br />
  
</div>
</div>

<h1 id="schedule">Schedule</h1>
<div style="text-align: left; max-width: 800px; margin: auto;">
<style>
            /* Table styling */
            table {
                width: 80%;
                margin: 20px auto;
                border-collapse: collapse;
                border: 1px solid #ddd; /* Add border to table */
            }
            th, td {
                padding: 12px;
                text-align: left;
                border: 1px solid #ddd; /* Add border to cells */
            }
            th {
                background-color: #f2f2f2;
            }
</style>


<ul>
  <li><strong>Date:</strong> June 12, 2024</li>
  <li><strong>Time:</strong> 9:00 AM - 12:30 PM</li>
  <li><strong>Location:</strong> </li>
</ul>
  
  <table>
                <tr>
                    <th> Time </th>
                    <th> Instructor </th>
                    <th> Title </th>
                </tr>
                <tr>
                    <td> 9:00 AM </td>
                    <td> Richard Hartley </td>
                    <td> <a href="DiffusionMathematics.pdf"> Mathematics of Diffusion Models </a></td>
                </tr>
                <tr>
                    <td> 9:45 AM </td>
                    <td> Srikumar Ramalingam </td>
                    <td> <a href="ECCV_2024_Tutorial_Cornerstones.pdf"> Efficient methods and cornerstones of text-to-image Generation </a> </td>
                </tr>
                <tr>
                    <td> 10:30 AM </td>
                    <td> Break </td>
                    <td>  </td>
                </tr>
                    <tr>
                    <td> 10:45 AM </td>
                    <td> Sadeep Jayasumana </td>
                    <td> <a href="Continuous_MRF.pdf"> Continuous MRF and FoE model for t2i Generation </a></td>
                </tr>
                <tr>
                    <td> 11:30 AM </td>
                    <td> Ameesh Makadia </td>
                    <td> <a href="Video_3D_generation.pdf">Efficient Text-to-3D and Text-to-Video generation</a>  </td>
                </tr>
                </table>

        </section>
        <section id="tutorial-content">
            <h1> Tutorial Contents </h1>
            <div style="text-align: left; max-width: 800px; margin: auto;">
            <b> Mathematics of Diffusion Models </b>  
            <p> We will cover the mathematics/fundamentals of diffusion models [6], which is the building block for many generative methods. More emphasis will be given on the underlying theory/fundamentals, which has received minimal attention in the community.  </p>
            <b> Efficient methods and cornerstones of t2i Generation </b>
            <p> We will provide some background on the text-to-image generation and then go over temporal-distillation and MRF-based algorithms [3] for improving the efficiency of token-based methods such as Muse [1]..</p>
            <b> Continuous MRF and FoE model for t2i Generation </b>  
            <p> We will cover current metrics for image generation (such as FID) and improved metrics such as CMMD [4]. Newer methods to speedup diffusion models using MRF And Field of Experts models will be discussed.. </p>
            <b> Efficient Text-to-3D and Text-to-Video generation </b>  
            <p> We will be giving an overview of generative algorithms in 3D and video space, and particularly covering efficient algorithms driven by geometric priors for video generation [7].. </p>
        </section>     

    <section id="references">
        <h1> References </h1>
        <div style="text-align: left; max-width: 800px; margin: auto;">
        <p> 1.  Chang, H., Zhang, H., Barber, J., Maschinot, A., Lezama, J., Jiang, L., Yang, M.H., Murphy, K., Freeman, W.T., Rubinstein, M., Li, Y., Krishnan, D.: Muse: Text-to-image generation via masked generative transformers. ICML (2023) </p> 
        <p> 2.  Esteves, C., Suhail, M., Makadia, A.: Spectral image tokenizers (2024) </p>
        <p> 3.  Jayasumana, S., Glasner, D., Ramalingam, S., Veit, A., Chakrabarti, A., Kumar, S.: Markovgen: Structured prediction for efficient text-to-image generation (2023) </p>
        <p> 4.  Jayasumana, S., Ramalingam, S., Veit, A., Glasner, D., Chakrabarti, A., Kumar, S.: Rethinking fid: Towards a better evaluation metric for image generation (2024) </p>
        <p> 5.  Mitchel, T., Esteves, C., Makadia, A.: Single mesh diffusion models with field latents for texture generation. In: CVPR (2024) </p>
        <p> 6.  Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., Ganguli, S.: Deep unsupervised learning using nonequilibrium thermodynamics. In: Proceedings of the 32nd International Conference on Machine Learning (2015) </p>
        <p> 7.  Suhail, M., Esteves, C., Sigal, L., Makadia, A.: Four-plane factorized video autoencoders (2024) </p>
        <p> 8.  Vice, J., Akhtar, N., Hartley, R., Mian, A.: On the fairness, diversity and reliability of textto-image generative models (2024) </p>
        <p> 9.  Vice, J., Akhtar, N., Hartley, R., Mian, A.: Safety without semantic disruptions: Editingfree safe image generation via context-preserving dual latent reconstruction (2024) </p>
        <p> 10. Yang, Z., Yu, Z., Xu, Z., Singh, J., Zhang, J., Campbell, D., Tu, P., Hartley, R.: Impus: Image morphing with perceptually-uniform sampling using diffusion models (2024), </p>
        <p> 11. Ranasinghe, K., Jayasumana, S., Veit, A., Chakrabarti, A., Glasner, D., Ryoo, M., Ramalingam, S., Kumar, S., LatentCRF: Continuous CRF for Efficient Latent Diffusion, CVPR 2025 </p>
    </section>

        <section id="resources">
            <h2>Code Repository References</h2>
            <ul>
                <li><a href="https://github.com/google-research/google-research/tree/master/cmmd">CMMD</a></li>
                </ul>
        </section>
    </main>

    <footer>
        <p>&copy; 2025 Richard Hartley, Sadeep Jayasumana, Ameesh Makadia, Srikumar Ramalingam </p>
    </footer>

    <script src="script.js"></script>  </body>
</html>
