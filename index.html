<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tutorial Title - Organizer Name</title>
    <link rel="stylesheet" href="style.css"> </head>
    <title>Tutorial Schedule</title>
        <style>
            /* Table styling */
            table {
                width: 80%;
                margin: 20px auto;
                border-collapse: collapse;
                border: 1px solid #ddd; /* Add border to table */
            }
            th, td {
                padding: 12px;
                text-align: left;
                border: 1px solid #ddd; /* Add border to cells */
            }
            th {
                background-color: #f2f2f2;
            }
    </style>
    <title>Tutorial Content</title>
    <style>
        /* Basic styling (optional) */
        body {
            font-family: sans-serif;
            line-height: 1.6;
        }
        h2 {
            color: #333;
        }
    </style>
<body>
    <header>
        <h1> Tutorial T05: Efficient Text-to-Image and Text-to-3D modeling </h1>
        <h2> Organizers: Shobhita Sundaram, Sadeep Jayasumana, Varun Jampani, Dilip Krishnan, Srikumar Ramalingam </h2>
        <h2> Date: September 29, 2024 </h2>
        <h2> Room: Amber 3</h2>
    </header>

    <main>
        <section id="tutorial-schedule">
            <h2>Tutorial Schedule</h2>
            <table>
                <tr>
                    <th> Time </th>
                    <th> Instructor </th>
                    <th> Title </th>
                </tr>
                <tr>
                    <td>9:00 AM</td>
                    <td> Organizers </td>
                    <td> Overview of the Tutorial </td>
                </tr>
                <tr>
                    <td> 9:15 AM </td>
                    <td> Srikumar Ramalingam </td>
                    <td> Introduction to text-to-image models </td>
                </tr>
                <tr>
                    <td> 10:00 AM </td>
                    <td> Shobhita Sundaram </td>
                    <td> Image Evaluation Methods </td>
                </tr>
                <tr>
                    <td> 10:30 AM </td>
                    <td> Break </td>
                    <td>  </td>
                </tr>
                <tr>
                    <td> 11:00 AM </td>
                    <td> Varun Jampani </td>
                    <td> Thinking Slow and Fast: Recent Trends in 3D Generative Models </td>
                </tr>
                <tr>
                    <td> 11:30 AM </td>
                    <td> Dilip Krishnan </td>
                    <td> Parallel Decoding and Image Generation </td>
                </tr>
                <tr>
                    <td> 12:00 AM </td>
                    <td> Sadeep Jayasumana </td>
                    <td> Structured Prediction Algorithms for Fast Image Generation </td>
                </tr>
                <tr>
                    <td> 12:30 AM </td>
                    <td> Discussion </td>
                    <td> Open Problems </td>
                </tr>
                </table>
        </section>
        <section id="tutorial-content">
            <h1> Tutorial Contents </h1>
            <b> Introduction to text-to-image models </b>  
            <p> We will cover the basics and fundamentals of diffusion and token-based image generation models such as Stable diffusion, Imagen, DALL-E, and Parti. We will be looking at both pixel-based and token-based diffusion models. We will also discuss evaluation metrics for text-to-image models, such as FID and CMMD. </p>
            <b> Parallel decoding and image generation </b>  
            <p> We will be focusing on existing methods for token-based image generation that exploits non-autoregressive techniques for achieving speedup. In particular, we will take a closer look at techniques such as MaskGIT and Muse that exploit progressive parallel decoding methods to produce high quality images more efficiently than autoregressive methods such as Parti. </p>
            <b> Fast Image Generation Techniques </b>  
            <p> We will cover current metrics for image generation (such as FID) and popular image similarity and quality assessment metrics, such as LPIPS \cite{zhang2018perceptual}. We will also discuss recent, efficient image similarity metrics, such as DreamSim, that are trained using synthetic data and parameter efficient fine-tuning of large ViT backbones. </p>
            <b> Thinking Slow and Fast: Recent Trends in 3D Generative Models </b>  
            <p> Extending text-to-image, there are several newer methods that focus on other modalities such as text-to-3D. We will be discussing the basics of text-to-3D algorithms such as repurposing text-to-image models for multi-view generation, as well as efficient ways to directly predict 3D models from a single image within a few seconds. </p>
        </section>     

    <section id="references">
        <h1> References </h1>
        <p> 1.  Chang,  H.,  Zhang,  H.,  Barber,  J.,  Maschinot,  A.,  Lezama,  J.,  Jiang,  L.,  Yang,M.H., Murphy, K., Freeman, W.T., Rubinstein, M., Li, Y., Krishnan, D.: Muse:Text-to-image generation via masked generative transformers. ICML (2023) </p> 
        <p> 2.  Chang, H., Zhang, H., Jiang, L., Liu, C., Freeman, W.T.: Maskgit: Masked gener-ative image transformer. In: CVPR (2022) </p>
        <p> 3.  Fu*,  S.,  Tamir*,  N.,  Sundaram*,  S.,  Chai,  L.,  Zhang,  R.,  Dekel,  T.,  Isola,  P.:Dreamsim:  Learning  new  dimensions  of  human  visual  similarity  using  syntheticdata. In: NeurIPS (2023) </p>
        <p> 4.  Heusel,  M.,  Ramsauer,  H.,  Unterthiner,  T.,  Nessler,  B.,  Hochreiter,  S.:  GANsTrained  by  a  Two  Time-Scale  Update  Rule  Converge  to  a  Local  Nash  Equilib-rium (2018) </p>
        <p> 5.  Jayasumana, S., Glasner, D., Ramalingam, S., Veit, A., Chakrabarti, A., Kumar,S.: Markovgen: Structured prediction for efficient text-to-image generation (2023) </p>
        <p> 6.  Jayasumana, S., Ramalingam, S., Veit, A., Glasner, D., Chakrabarti, A., Kumar,S.: Rethinking fid: Towards a better evaluation metric for image generation (2024) </p>
        <p> 7.  Midjourney: (2022), https:://www.midjourney.com8.  Poole, B., Jain, A., Barron, J.T., Mildenhall, B.: Dreamfusion: Text-to-3d using2d diffusion (2022) </p>
        <p> 9.  Raj,  A.,  Kaza,  S.,  Poole,  B.,  Niemeyer,  M.,  Mildenhall,  B.,  Ruiz,  N.,  Zada,  S.,Aberman,  K.,  Rubenstein,  M.,  Barron,  J.,  Li,  Y.,  Jampani,  V.:  Dreambooth3d:Subject-driven text-to-3d generation. ICCV (2023) </p>
        <p> 10.  Ramesh,  A.,  Dhariwal,  P.,  Nichol,  A.,  Chu,  C.,  Chen,  M.:  Hierarchical  text-conditional image generation with clip latents. preprint (2022), [arxiv:2204.06125] </p>
        <p> 11.  Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolutionimage synthesis with latent diffusion models. In: CVPR (2022) </p>
        <p> 12.  Ruiz, N., Li, Y., Jampani, V., Pritch, Y., Rubinstein, M., Aberman, K.: Dream-booth:  Fine  tuning  text-to-image  diffusion  models  for  subject-driven  generation(2022) </p>
        <p> 13.  Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., Ghasemipour,S.K.S., Ayan, B.K., Mahdavi, S.S., Lopes, R.G., Salimans, T., Ho, J., Fleet, D.J.,Norouzi, M.: Photorealistic text-to-image diffusion models with deep language un-derstanding. preprint (2022), [arXiv:2205.11487] </p>
        <p> 14.  Salimans, T., Ho, J.: Progressive distillation for fast sampling of diffusion models.In: ICLR (2022) </p>
        <p> 15.  Yu, J., Xu, Y., Koh, J.Y., Luong, T., Baid, G., Wang, Z., Vasudevan, V., Ku, A.,Yang,  Y.,  Ayan,  B.K.,  Hutchinson,  B.,  Han,  W.,  Parekh,  Z.,  Li,  X.,  Zhang,  H.,Baldridge, J., Wu, Y.: Scaling autoregressive models for content-rich text-to-imagegeneration. In: ICML (2022) </p>
        <p> 16.  Zhang,  R.,  Isola,  P.,  Efros,  A.A.,  Shechtman,  E.,  Wang,  O.:  The  unreasonable effectiveness of deep features as a perceptual metric. In: CVPR (2018) </p>
    </section>

        <section id="resources">
            <h2>Code Repository References</h2>
            <ul>
                <li><a href="https://github.com/google-research/google-research/tree/master/cmmd">CMMD</a></li>
                <li><a href="https://github.com/ssundaram21/dreamsim">DreamSim</a></li>
                </ul>
        </section>
    </main>

    <footer>
        <p>&copy; 2024 Shobhita Sundaram, Sadeep Jayasumana, Varun Jampani, Dilip Krishnan, Srikumar Ramalingam </p>
    </footer>

    <script src="script.js"></script>  </body>
</html>
